{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (0.0.230)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (2.0.18)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/lib/python3/dist-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/lib/python3/dist-packages (from langchain) (2.25.1)\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (1.26.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/lib/python3/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: requests, regex, tiktoken\n",
      "Successfully installed regex-2023.6.3 requests-2.31.0 tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =50\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"NLP stands for Natural Language Processing. \\\n",
    " It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction \\\n",
    " between computers and human language. \\\n",
    " NLP aims to enable computers to understand, interpret, \\\n",
    " and generate natural language in a way that is meaningful and useful to humans.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.  NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "print(c_splitter.split_text(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is', 'is a subfield of artificial intelligence (AI) and', 'and linguistics that focuses on the interaction', 'between computers and human language.  NLP aims', 'to enable computers to understand, interpret,', 'and generate natural language in a way that is', 'is meaningful and useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "print(r_splitter.split_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing. It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction between computers and human language. NLP aims to enable computers to understand, interpret, and generate natural language in a way that is meaningful and', 'useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "print(c_splitter.split_text(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.  NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and', 'useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "print(r_splitter.split_text(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP stands for Natural Language Processing.',\n",
       " 'It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.',\n",
       " 'NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and useful to humans.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
