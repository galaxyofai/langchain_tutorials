{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (0.0.230)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (2.0.18)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/lib/python3/dist-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/lib/python3/dist-packages (from langchain) (2.25.1)\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (1.26.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/lib/python3/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/galaxy_of_ai/.local/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: requests, regex, tiktoken\n",
      "Successfully installed regex-2023.6.3 requests-2.31.0 tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =50\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"NLP stands for Natural Language Processing. \\\n",
    " It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction \\\n",
    " between computers and human language. \\\n",
    " NLP aims to enable computers to understand, interpret, \\\n",
    " and generate natural language in a way that is meaningful and useful to humans.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.  NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "print(c_splitter.split_text(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is', 'is a subfield of artificial intelligence (AI) and', 'and linguistics that focuses on the interaction', 'between computers and human language.  NLP aims', 'to enable computers to understand, interpret,', 'and generate natural language in a way that is', 'is meaningful and useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "print(r_splitter.split_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing. It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction between computers and human language. NLP aims to enable computers to understand, interpret, and generate natural language in a way that is meaningful and', 'useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "print(c_splitter.split_text(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP stands for Natural Language Processing.  It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.  NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and', 'useful to humans.']\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "print(r_splitter.split_text(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP stands for Natural Language Processing.',\n",
       " 'It is a subfield of artificial intelligence (AI) and linguistics that focuses on the interaction  between computers and human language.',\n",
       " 'NLP aims to enable computers to understand, interpret,  and generate natural language in a way that is meaningful and useful to humans.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yt_dlp\n",
      "  Using cached yt_dlp-2023.7.6-py2.py3-none-any.whl (3.0 MB)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pycryptodomex in /usr/lib/python3/dist-packages (from yt_dlp) (3.11.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from yt_dlp) (2020.6.20)\n",
      "Collecting mutagen\n",
      "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 KB\u001b[0m \u001b[31m853.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: brotli in /usr/lib/python3/dist-packages (from yt_dlp) (1.0.9)\n",
      "Collecting websockets\n",
      "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Installing collected packages: pydub, websockets, mutagen, yt_dlp\n",
      "Successfully installed mutagen-1.46.0 pydub-0.25.1 websockets-11.0.3 yt_dlp-2023.7.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yt_dlp pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import openai\n",
    "import os\n",
    "__ = load_dotenv('.env') #read local .env file\n",
    "openai.api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "URL=\"https://www.youtube.com/shorts/LZ0Z8PE7dWo\"\n",
    "save_dir=\"./audio/\"\n",
    "\n",
    "loader=GenericLoader(YoutubeAudioLoader([URL],save_dir),OpenAIWhisperParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/shorts/LZ0Z8PE7dWo\n",
      "[youtube] LZ0Z8PE7dWo: Downloading webpage\n",
      "[youtube] LZ0Z8PE7dWo: Downloading ios player API JSON\n",
      "[youtube] LZ0Z8PE7dWo: Downloading android player API JSON\n",
      "[youtube] LZ0Z8PE7dWo: Downloading m3u8 information\n",
      "[info] LZ0Z8PE7dWo: Downloading 1 format(s): 140\n",
      "[download] ./audio//introduction of galaxyofai.m4a has already been downloaded\n",
      "[download] 100% of  405.33KiB\n",
      "[ExtractAudio] Not converting audio ./audio//introduction of galaxyofai.m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "[Document(page_content='Hello learners. Welcome to the Galaxy of AI. Galaxy of AI is a blog about artificial intelligence, machine learning, deep learning, and data science. This is the platform to share knowledge and experience with all of the developers community. We hope our articles will save you time and get things done quickly. Happy learning and keep learning. Thank you.', metadata={'source': 'audio/introduction of galaxyofai.m4a', 'chunk': 0})]\n"
     ]
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello learners. Welcome to the Galaxy of AI. Galaxy of AI is a blog about artificial intelligence, m'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
